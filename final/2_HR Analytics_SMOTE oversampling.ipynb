{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c_/xfclsffs46x_pr2y70z2qfsm0000gn/T/ipykernel_53909/397798031.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss, confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from copy import deepcopy\n",
    "import warnings, graphviz, optuna\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style='white')\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['axes.titleweight'] = 'bold'\n",
    "plt.rcParams['axes.labelsize'] = 13\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "RANDOM_STATE = 0\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    trn = pd.read_csv('aug_train.csv')\n",
    "    tst = pd.read_csv('aug_test.csv')\n",
    "    tst_answer = np.load('jobchange_test_target_values.npy')\n",
    "    tst['target'] = tst_answer\n",
    "    trn.drop('enrollee_id', axis=1, inplace=True)\n",
    "    tst.drop('enrollee_id', axis=1, inplace=True)\n",
    "    trn['city'] = trn['city'].map(lambda x: 'city_'+str(int(x[5:])).zfill(3))\n",
    "    tst['city'] = tst['city'].map(lambda x: 'city_'+str(int(x[5:])).zfill(3))\n",
    "\n",
    "    # 모든 Null 값을 Missing으로 변경합니다.\n",
    "    for col in tst.columns:\n",
    "        trn[col].fillna('Missing', inplace=True)\n",
    "        tst[col].fillna('Missing', inplace=True)\n",
    "\n",
    "    # Missing 값의 갯수 Feature 생성\n",
    "    trn['num_missing'] = (trn=='Missing').sum(axis=1)\n",
    "    tst['num_missing'] = (tst=='Missing').sum(axis=1)\n",
    "    return trn, tst\n",
    "\n",
    "def labelencoder(train, test):\n",
    "    # normianl feature는 labelencoder로 처리\n",
    "    norminal = ['city', 'gender', 'relevent_experience', 'major_discipline', 'company_type']\n",
    "    for col in norminal:\n",
    "        le = LabelEncoder()\n",
    "        train[col] = le.fit_transform(train[col])\n",
    "        test[col] = le.transform(test[col])\n",
    "\n",
    "    # ordinal feature는 자체적으로 생성한 dictionary로 처리합니다\n",
    "    ordinal = {\n",
    "        'enrolled_university':{'Full time course':3, 'Part time course':2, 'no_enrollment':1, 'Missing':0},\n",
    "        'education_level':{'Phd':5, 'Masters':4, 'Graduate':3, 'High School':2, 'Primary School':1, 'Missing':0},\n",
    "        'experience':{\n",
    "            '>20':22, '20':21, '19':20, '18':19, '17':18, '16':17, '15':16, '14':15, '13':14, '12':13, '11':12, '10':11,\n",
    "            '9':10, '8':9, '7':8, '6':7, '5':6, '4':5, '3':4, '2':3, '1':2 , '<1':1, 'Missing':0\n",
    "        },\n",
    "        'company_size':{'10000+':8, '5000-9999':7, '1000-4999':6, '500-999':5, '100-500':4, '50-99':3, '10/49':2, '<10':1, 'Missing':0},\n",
    "        'last_new_job':{'>4':6, '4':5, '3':4, '2':3, '1':2, 'never':1, 'Missing':0}\n",
    "    }\n",
    "    for col in ordinal:\n",
    "        train[col] = train[col].map(ordinal[col])\n",
    "        test[col] = test[col].map(ordinal[col])\n",
    "    return train, test\n",
    "\n",
    "def oversampling(data, features):\n",
    "    data_features, data_targets = SMOTE(random_state=RANDOM_STATE).fit_resample(data[features], data.target)\n",
    "    data_targets = data_targets.to_frame()\n",
    "    data_targets.columns = ['target']\n",
    "    data = pd.concat([data_features, data_targets], axis=1)\n",
    "    return data\n",
    "\n",
    "def show_target_dist(df_list, title_list):\n",
    "    fig, axes = plt.subplots(figsize=(12, 4), ncols=2)\n",
    "    for n, df in enumerate(df_list):\n",
    "        data = df['target'].value_counts()    \n",
    "        ax = axes[n]\n",
    "        ax.bar([0, 1], data.values, width=0.6, color=['lightgrey', '#2f5597'], ec='black', lw=0.5)\n",
    "        for idx in data.index:\n",
    "            ax.text(\n",
    "                idx, data[idx]+200, format(data[idx],\",\"), fontsize=11, fontweight='bold',\n",
    "                ha='center', va='bottom'\n",
    "            )\n",
    "        ax.set_xticks([0, 1])\n",
    "        ax.set_xticklabels(['0: Not looking for a job change', '1: looking for a job change'])\n",
    "        ax.set_yticklabels(list(format(int(x), \",\") for x in ax.get_yticks()))\n",
    "        ax.set_ylim(0, 17000)\n",
    "        ax.set_xlabel('Target')\n",
    "        ax.set_ylabel('People')\n",
    "        ax.set_title(title_list[n])\n",
    "    plt.show()\n",
    "\n",
    "def return_model_result(model_list, trn, trn_over, tst):    \n",
    "    result = np.zeros((len(model_list), 6))    \n",
    "    preds = []\n",
    "    for n, model in enumerate(model_list):                \n",
    "        model_ = deepcopy(model)\n",
    "        model.fit(trn[features], trn['target'])                \n",
    "        preds.append(model.predict_proba(tst[features]))\n",
    "        \n",
    "        model = deepcopy(model_)\n",
    "        model.fit(trn_over[features], trn_over['target'])                        \n",
    "        preds.append(model.predict_proba(tst[features]))\n",
    "    return preds\n",
    "\n",
    "def make_result_df(model_names, preds, tst):\n",
    "    result_list = []\n",
    "    for idx in range(0, len(preds), 2):\n",
    "        result_list.append(accuracy_score(tst.target, np.argmax(preds[idx], axis=1)))\n",
    "        result_list.append(accuracy_score(tst.target, np.argmax(preds[idx+1], axis=1)))\n",
    "        result_list.append(log_loss(tst.target, preds[idx]))\n",
    "        result_list.append(log_loss(tst.target, preds[idx+1]))\n",
    "        result_list.append(roc_auc_score(tst.target, np.argmax(preds[idx], axis=1)))\n",
    "        result_list.append(roc_auc_score(tst.target, np.argmax(preds[idx+1], axis=1)))\n",
    "    result = np.array(result_list).reshape(len(model_list), -1)    \n",
    "    result = pd.DataFrame(\n",
    "        index=model_names, data=result,\n",
    "        columns=[\n",
    "            'acc_test', 'acc_test(over)', 'log_loss_test', 'log_loss_test(over)',\n",
    "            'roc_score_test', 'roc_score_test(over)'\n",
    "        ]\n",
    "    )\n",
    "    return result\n",
    "\n",
    "def show_heatmap_roc(model_names, preds, tst):\n",
    "    for idx in range(len(model_names)):        \n",
    "        fig, axes = plt.subplots(figsize=(15, 4), ncols=3)        \n",
    "        sns.heatmap(\n",
    "            confusion_matrix(tst.target, np.argmax(preds[2*idx], axis=1)),\n",
    "            ax=axes[0], annot=True, fmt=\",\", cbar=False,\n",
    "            cmap='Blues', annot_kws={'fontweight':'bold'}\n",
    "        )\n",
    "        sns.heatmap(\n",
    "            confusion_matrix(tst.target, np.argmax(preds[2*idx+1], axis=1)),\n",
    "            ax=axes[1], annot=True, fmt=\",\", cbar=False,\n",
    "            cmap='Blues', annot_kws={'fontweight':'bold'}\n",
    "        )\n",
    "        random_x = np.linspace(0, 1, 15)\n",
    "        random_y = np.linspace(0, 1, 15)\n",
    "        axes[2].plot(random_x, random_y, label='Random', color='black', ls=':', lw=1.5)\n",
    "        \n",
    "        n = 0\n",
    "        colors=['#d1495b', '#00798c']\n",
    "        for pred, label in zip([preds[2*idx], preds[2*idx+1]], ['train', 'train_over']):    \n",
    "            fprs, tprs, _ = roc_curve(tst.target, pred[:, 1])     \n",
    "            axes[2].plot(fprs, tprs, label=label, color=colors[n])\n",
    "            axes[2].fill_between(fprs, tprs, color=colors[n], alpha=0.2)\n",
    "            n += 1\n",
    "        axes[2].fill_between(random_x, random_y, color='white')\n",
    "            \n",
    "        axes[0].set_title(model_names[idx] + ' Train')\n",
    "        axes[1].set_title(model_names[idx] + ' Train(over)')\n",
    "        axes[0].set_xlabel('Predicted Label')\n",
    "        axes[0].set_ylabel('True Label')        \n",
    "        axes[1].set_xlabel('Predicted Label')\n",
    "        axes[1].set_ylabel('True Label')        \n",
    "        axes[2].legend()\n",
    "        axes[2].set_title('ROC_CURVE')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, tst = load_data()\n",
    "trn, tst = labelencoder(trn, tst)\n",
    "features = trn.drop('target', axis=1).columns\n",
    "trn_over = oversampling(trn, features)\n",
    "print(trn.shape, trn_over.shape, tst.shape)\n",
    "show_target_dist([trn, trn_over], ['Original Target distribution', 'Oversampling Target distribution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline 모델 리스트\n",
    "model_list = [\n",
    "    DecisionTreeClassifier(max_depth=5, random_state=RANDOM_STATE),\n",
    "    RandomForestClassifier(n_jobs=-1, random_state=RANDOM_STATE),\n",
    "    XGBClassifier(n_jobs=-1), LGBMClassifier(n_jobs=-1)\n",
    "]\n",
    "model_names = ['DecisionTree', 'RandomForest', 'XGBClassifier', 'LGBMClassifier']\n",
    "preds = return_model_result(model_list, trn, trn_over, tst)\n",
    "result_df = make_result_df(model_names, preds, tst)\n",
    "# 각 모델의 원래 train 데이터셋의 결과, oversampling train 데이터셋의 결과를 반환합니다. 크기는 모델 갯수 X 2\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_heatmap_roc(model_names, preds, tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE Oversampling은 모델의 성능을 오히려 떨어트렸습니다."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
